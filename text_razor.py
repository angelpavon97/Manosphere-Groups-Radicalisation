import textrazor
from IncelsSQL import IncelsSQL
from config import textrazor_key
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk import word_tokenize, pos_tag
from nltk.stem.porter import *
import scipy.sparse
import pickle

def get_url_regex(): # https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/11332580
    regex = r'('
    # Scheme (HTTP, HTTPS, FTP and SFTP):
    regex += r'(?:(https?|s?ftp):\/\/)?'
    # www:
    regex += r'(?:www\.)?'
    regex += r'('
    # Host and domain (including ccSLD):
    regex += r'(?:(?:[A-Z0-9][A-Z0-9-]{0,61}[A-Z0-9]\.)+)'
    # TLD:
    regex += r'([A-Z]{2,6})'
    # IP Address:
    regex += r'|(?:\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'
    regex += r')'
    # Port:
    regex += r'(?::(\d{1,5}))?'
    # Query path:
    regex += r'(?:(\/\S+)*)'
    regex += r')'

    return regex

def remove_urls(text):
    regex = get_url_regex()
    find_urls = re.compile(regex, re.IGNORECASE)

    found_urls = [f[0] for f in find_urls.findall(text)]
    
    for url in found_urls:
        text = text.replace(url, '')

    return text

def process_text(text):

    # Remove urls
    text = remove_urls(text)

    # Remove signs
    text = text.replace('-', '')
    text = text.replace('+', '')

    # Tokenization
    tokenized = word_tokenize(text)

    # Stop words
    stop_words = stopwords.words('english')
    stop_words.extend(['https', 'http', 'www', 'html', 'get_simple'])

    # Removing stop words and keeping adj and nouns
    nouns_adj = [word for word in tokenized if word not in stop_words]

    return ' '.join(nouns_adj)

def get_df_example():

    urls = ['google.es',
            'youtube.com',
            'twitter.com',
            'wikipedia.com',
            'facebook.com']
    comments = ['Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, a search engine, cloud computing, software, and hardware. It is considered one of the five Big Tech companies alongside Amazon, Facebook, Apple, and Microsoft.',
                'YouTube is an online video platform owned by Google. It is the second most-visited website in the world.[7] In 2019, more than 500 hours of video content were uploaded to YouTube servers every minute. YouTube provides several ways to watch videos, including the website, the mobile apps, and permitting other websites to embed them. Available content includes video clips, TV show clips, music videos, short and documentary films, audio recordings, movie trailers, live streams, video blogs, and short original videos. Most content is generated by individuals, but media corporations also publish videos. Besides watching and uploading, registered users can comment on videos, rate them, create playlists, and subscribe to other users.',
                'Twitter is an American microblogging and social networking service on which users post and interact with messages known as "tweets". Registered users can post, like and retweet tweets, but unregistered users can only read them. Users access Twitter through its website interface or its mobile-device application software ("app"), though the service could also be accessed via SMS before April 2020. Twitter, Inc. is based in San Francisco, California, and has more than 25 offices around the world. Tweets were originally restricted to 140 characters, but was doubled to 280 for non-CJK languages in November 2017. Audio and video tweets remain limited to 140 seconds for most accounts. ',
                'Wikipedia is a free, multilingual open-collaborative online encyclopedia created and maintained by a community of volunteer contributors using a wiki-based editing system. Wikipedia is the largest general reference work on the Internet, and one of the 15 most popular websites as ranked by Alexa; in 2021, it was ranked as the 13th most-visited. The project carries no advertisements and is hosted by the Wikimedia Foundation, an American non-profit organization funded mainly through donations.',
                'Facebook (stylized as facebook) is an American online social media and social networking service based in Menlo Park, California, and a flagship service of the namesake company Facebook, Inc. It was founded by Mark Zuckerberg, along with fellow Harvard College students and roommates Eduardo Saverin, Andrew McCollum, Dustin Moskovitz, and Chris Hughes. The founders of Facebook initially limited membership to Harvard students. Membership was expanded to Columbia, Stanford, and Yale before being expanded to the rest of the Ivy League, MIT, NYU, Boston University, then various other universities in the United States and Canada, and lastly high school students. Since 2006, anyone who claims to be at least 13 years old has been allowed to become a registered user of Facebook, though this may vary depending on local laws. The name comes from the face book directories often given to American university students. '
    ]

    d = {'urls': urls, 'comments': comments}
    df = pd.DataFrame(data=d)

    return df

def get_df(paths=False):

    connection = IncelsSQL()
    if paths == False:
        data_dict = connection.get_comments_from_url_table()
    else:
        data_dict = connection.get_comments_from_path_table()

    df = pd.DataFrame(data_dict.items(), columns=['urls', 'comments'])

    return df

def apply_text_razor(text, url='Not specified'):
    textrazor.api_key = textrazor_key

    client = textrazor.TextRazor(extractors=["topics"])

    try:
        response = client.analyze(text)
    except:
        print("Error in url:", url)
        return []

    topics = []    
    for topic in response.topics():
        if topic.score >= 0.5:
            topics.append(topic.label)

    return topics

def save_topics(topics_dict, paths = False):

    if paths == False:
        f = open('./topic_modeling/text_razor/URLs_topics.txt' ,'w')
    else:
        f = open('./topic_modeling/text_razor/paths_topics.txt' ,'w')

    for url, topics in topics_dict.items():
        f.write(url + '\t\t' + ', '.join(topics) + '\n')

    print('Topics saved successfully.')
    f.close()
    

if __name__ == "__main__":

    # Set paths
    paths = True

    # Get data
    print('Getting data...')
    df = get_df(paths)
    print(df)

    # Process comments
    print('Processing comments...')
    processed_comments = pd.DataFrame(df.comments.apply(process_text))
    processed_comments.index = df.urls
    print(processed_comments)

    # Getting topics
    topics_dict = {}

    for index, row in processed_comments.iterrows():
        url = index
        text = row['comments']

        print(url)
        topics = apply_text_razor(text, url=url)
        topics_dict[url] = topics

    # Save topics
    save_topics(topics_dict, paths)


        